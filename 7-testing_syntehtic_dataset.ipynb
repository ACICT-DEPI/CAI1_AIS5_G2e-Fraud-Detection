{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/creditcard_synthetic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Selecting Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(\"Class\", axis=1)\n",
    "y = df[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiction Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    # recall_score,\n",
    "    # precision_score,\n",
    "    # f1_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "# from sklearn.metrics._plot.confusion_matrix import (\n",
    "#     confusion_matrix,\n",
    "# )\n",
    "\n",
    "\n",
    "def print_metrics(y_true, y_pred):\n",
    "    print(\"Classification Report: \\n\", classification_report(y_true, y_pred))\n",
    "    print(\"Model Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "    print(\"ROC AUC: \", roc_auc_score(y_true, y_pred))\n",
    "    print(\"Confusion matrix: \\n\", confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = joblib.load(\"models/logistic_regression_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.65      0.72      1000\n",
      "           1       0.71      0.85      0.77      1000\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.76      0.75      0.75      2000\n",
      "weighted avg       0.76      0.75      0.75      2000\n",
      "\n",
      "Model Accuracy:  0.752\n",
      "ROC AUC:  0.752\n",
      "Confusion matrix: \n",
      " [[652 348]\n",
      " [148 852]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_lr.predict(x)\n",
    "\n",
    "print_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = joblib.load(\"models/knn_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1000\n",
      "           1       0.83      0.01      0.01      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.67      0.50      0.34      2000\n",
      "weighted avg       0.67      0.50      0.34      2000\n",
      "\n",
      "Model Accuracy:  0.502\n",
      "ROC AUC:  0.502\n",
      "Confusion matrix: \n",
      " [[999   1]\n",
      " [995   5]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_knn.predict(x)\n",
    "\n",
    "print_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dtc = joblib.load(\"models/dtc_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.97      0.67      1000\n",
      "           1       0.66      0.06      0.10      1000\n",
      "\n",
      "    accuracy                           0.51      2000\n",
      "   macro avg       0.58      0.51      0.38      2000\n",
      "weighted avg       0.58      0.51      0.38      2000\n",
      "\n",
      "Model Accuracy:  0.5135\n",
      "ROC AUC:  0.5135\n",
      "Confusion matrix: \n",
      " [[972  28]\n",
      " [945  55]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_dtc.predict(x)\n",
    "\n",
    "print_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfc = joblib.load(\"models/rfc_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n",
      "Model Accuracy:  0.5\n",
      "ROC AUC:  0.5\n",
      "Confusion matrix: \n",
      " [[1000    0]\n",
      " [1000    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/m/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/m/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_rfc.predict(x)\n",
    "\n",
    "print_metrics(y, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
